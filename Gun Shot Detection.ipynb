{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting the audio files into segments of same length\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += int(window_size / 2)\n",
    "\n",
    "def extract_features(df,bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1) # setting sound clip length to 20480 frames\n",
    "    labels = []\n",
    "    log_specgrams = []\n",
    "    log_mfccs = []\n",
    "    for index in df.index.tolist():\n",
    "        fn = df.loc[index]['filename'] # getting filenames from csv file\n",
    "        try:sound_clip,s = librosa.load('SoundData/Train/'+fn)\n",
    "        except FileNotFoundError:\n",
    "            print(fn)\n",
    "        label = df.loc[index]['classID']-1\n",
    "        for (start,end) in windows(sound_clip,window_size):\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "                logspec,logmfcc = audioFeatures(signal,s)\n",
    "                log_specgrams.append(logspec)\n",
    "                log_mfccs.append(logmfcc)\n",
    "                labels.append(label)\n",
    "\n",
    "    features1 = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features2 = np.asarray(log_mfccs).reshape(len(log_mfccs),bands,frames,1)\n",
    "    features = np.concatenate((features1,features2),axis=3)\n",
    "    return features, np.array(labels,dtype = np.int)\n",
    "    \n",
    "def audioFeatures(signal,sample_rate,bands = 60):\n",
    "    melspec = librosa.feature.melspectrogram(signal, n_mels=bands)\n",
    "    logspec = librosa.amplitude_to_db(melspec)\n",
    "    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=bands)\n",
    "    logmfcc = librosa.amplitude_to_db(mfccs).T.flatten()[:, np.newaxis].T\n",
    "    return logspec, logmfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "audioFile = pd.read_csv('/Users/qizhilin/Downloads/SoundData/audio.csv')\n",
    "audio_train = pd.DataFrame()\n",
    "audio_test = pd.DataFrame()\n",
    "# making sure there are enough dataset for each label\n",
    "for i in range(1,12):\n",
    "    _train, _test = train_test_split(audioFile[audioFile['classID']==i], test_size=0.3)\n",
    "    audio_train = audio_train.append(_train)\n",
    "    audio_test = audio_test.append(_test)\n",
    "train_features, train_labels = extract_features(audio_train)\n",
    "test_features, test_labels = extract_features(audio_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 60, 41, 2])\n",
    "    #build two CNN layers. Set ksize as [9,7].\n",
    "    conv1 = tf.layers.conv2d(input_layer,64, [9,7],\n",
    "                           padding=\"same\",\n",
    "                           activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    conv2 = tf.layers.conv2d(pool1,128, [9,7],\n",
    "                           padding=\"same\",\n",
    "                           activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    # output size 15*11*128\n",
    "    shape = conv2.get_shape().as_list()\n",
    "    pool2_flat = tf.reshape(conv2, [-1, shape[1] * shape[2] * shape[3]])\n",
    "    # build fully connected layers\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=11)\n",
    "    #use argmax to get the maximum output among labels as prediction class\n",
    "    #use softmax to compute probilities of each label for each input\n",
    "    predictions = {\"classes\": tf.argmax(input=logits, axis=1),\n",
    "                   \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")} \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    #use cross entropy to compute loss for classification \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits) \n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"], name=\"acc_op\")\n",
    "    eval_metric_ops = {\"accuracy\": accuracy}\n",
    "    tf.summary.scalar('accuracy', accuracy[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'Downloads/A', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x109f3cc50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:loss = 5.480645179748535, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 77 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.128936\n",
      "INFO:tensorflow: (775.603 sec)\n",
      "INFO:tensorflow:loss = 1.744231104850769, step = 101 (775.598 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 161 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.141841\n",
      "INFO:tensorflow: (705.000 sec)\n",
      "INFO:tensorflow:loss = 1.466784954071045, step = 201 (705.000 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 247 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.143518\n",
      "INFO:tensorflow: (696.773 sec)\n",
      "INFO:tensorflow:loss = 0.38096579909324646, step = 301 (696.773 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 331 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.127374\n",
      "INFO:tensorflow: (785.125 sec)\n",
      "INFO:tensorflow:loss = 0.26392921805381775, step = 401 (785.127 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 408 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 487 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.13149\n",
      "INFO:tensorflow: (760.479 sec)\n",
      "INFO:tensorflow:loss = 0.1653151661157608, step = 501 (760.479 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 566 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.11879\n",
      "INFO:tensorflow: (841.844 sec)\n",
      "INFO:tensorflow:loss = 0.08927963674068451, step = 601 (841.843 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 632 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 692 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.106688\n",
      "INFO:tensorflow: (937.291 sec)\n",
      "INFO:tensorflow:loss = 0.036126356571912766, step = 701 (937.291 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 771 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.133137\n",
      "INFO:tensorflow: (751.101 sec)\n",
      "INFO:tensorflow:loss = 0.02211083099246025, step = 801 (751.103 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 850 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.119728\n",
      "INFO:tensorflow: (835.245 sec)\n",
      "INFO:tensorflow:loss = 0.05759590119123459, step = 901 (835.244 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 922 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.128272\n",
      "INFO:tensorflow: (779.571 sec)\n",
      "INFO:tensorflow:loss = 0.04455122724175453, step = 1001 (779.571 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1068 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.109075\n",
      "INFO:tensorflow: (916.818 sec)\n",
      "INFO:tensorflow:loss = 0.0006503031472675502, step = 1101 (916.817 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1136 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.114997\n",
      "INFO:tensorflow: (869.601 sec)\n",
      "INFO:tensorflow:loss = 0.0006735867355018854, step = 1201 (869.601 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1203 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1278 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.114938\n",
      "INFO:tensorflow: (870.028 sec)\n",
      "INFO:tensorflow:loss = 0.0037863319739699364, step = 1301 (870.027 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1340 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.113842\n",
      "INFO:tensorflow: (878.420 sec)\n",
      "INFO:tensorflow:loss = 0.00015867147885728627, step = 1401 (878.420 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1412 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1497 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into Downloads/A/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00034988962579518557.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-20:31:35\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Downloads/A/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-22-20:32:13\n",
      "INFO:tensorflow:Saving dict for global step 1500: accuracy = 0.8311315, global_step = 1500, loss = 1.2462727\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: Downloads/A/model.ckpt-1500\n",
      "{'accuracy': 0.8311315, 'loss': 1.2462727, 'global_step': 1500}\n"
     ]
    }
   ],
   "source": [
    "# generate Estimator\n",
    "classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"Downloads/A\")\n",
    "tensors_to_log = {}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors_to_log, every_n_iter=100)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_features},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1500, \n",
    "    hooks=[logging_hook])\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_features},\n",
    "    y=test_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from Downloads/A/model.ckpt-1500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"Gunshot\"(100.0%),correct sound label is\"Gunshot\".\n",
      "\n",
      "Prediction is \"Jackhammer\"(100.0%),correct sound label is\"Jackhammer\".\n",
      "\n",
      "Prediction is \"Drilling\"(100.0%),correct sound label is\"Drilling\".\n",
      "\n",
      "Prediction is \"Engine Idling\"(100.0%),correct sound label is\"Engine Idling\".\n",
      "\n",
      "Prediction is \"Thunderstrom\"(99.9%),correct sound label is\"Thunderstrom\".\n",
      "\n",
      "Prediction is \"Church Bells\"(100.0%),correct sound label is\"Church Bells\".\n",
      "\n",
      "Prediction is \"Jackhammer\"(95.3%),correct sound label is\"Airplane\".\n",
      "\n",
      "Prediction is \"Airplane\"(95.3%),correct sound label is\"Train\".\n",
      "\n",
      "Prediction is \"Chainsaw\"(99.6%),correct sound label is\"Chainsaw\".\n",
      "\n",
      "Prediction is \"Fireworks\"(100.0%),correct sound label is\"Fireworks\".\n",
      "\n",
      "Prediction is \"Car Horn\"(99.5%),correct sound label is\"Car Horn\".\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# extract prediction file\n",
    "predictFile = pd.read_csv('/Users/qizhilin/Downloads/SoundData/predict.csv')\n",
    "predict_features, predict_labels = extract_features(predictFile)\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": predict_features},\n",
    "    y=predict_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "# make prediction\n",
    "predictions = classifier.predict(input_fn=pred_input_fn)\n",
    "expected_labels = {}\n",
    "class_dict = {0:'Thunderstrom',\n",
    "              1:'Fireworks',\n",
    "              2:'Chainsaw',\n",
    "              3:'Drilling',\n",
    "              4:'Engine Idling',\n",
    "              5:'Gunshot',\n",
    "              6:'Jackhammer',\n",
    "              7:'Airplane',\n",
    "              8:'Train',\n",
    "              9:'Church Bells',\n",
    "              10:'Car Horn'}\n",
    "for key in predict_labels:\n",
    "    expected_labels[key] = expected_labels.get(key, 0) + 1\n",
    "\n",
    "for k,v in expected_labels.items():\n",
    "    class_ids = []\n",
    "    valid_predict = []\n",
    "    prob = dict.fromkeys(class_dict.keys(),0)\n",
    "    for pred_dict in predictions:\n",
    "        class_id = pred_dict['classes']\n",
    "        class_ids.append(class_id)\n",
    "        probability = pred_dict['probabilities'][class_id]\n",
    "        if probability > 0.8: # drop out predictions that has confidence less than 80%\n",
    "            valid_predict.append(class_id)\n",
    "            prob[class_id]+=probability\n",
    "        label_counts = Counter(valid_predict)\n",
    "        top = label_counts.most_common(1) # get most common predictions of an input audio file\n",
    "        if len(class_ids)>=v:\n",
    "            break\n",
    "    final_prob = 100*prob[top[0][0]]/float(top[0][1]) # calculate the average probability of most common predictions\n",
    "    if final_prob <= 90:\n",
    "        print('\\nPrediction is \"Other sound\".')\n",
    "    else: print('\\nPrediction is \"{}\"({:.1f}%),correct sound label is\"{}\".'.format(class_dict[top[0][0]],\n",
    "                                                                               final_prob,class_dict[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
